{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.rnn_reg import EmbeddingDropout, WeightDrop, LockedDropout\n",
    "from fastai.torch_imports import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as spacy_STOPWORDS\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# pandas and plotting config\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = 'data'\n",
    "\n",
    "os.makedirs(f'{PATH}/models', exist_ok=True)\n",
    "os.makedirs(f'{PATH}/tmp', exist_ok=True)\n",
    "os.makedirs(f'{PATH}/submissions', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load data and define labels (ordering is important for competition submission!)\n",
    "\n",
    "*Note: We are also adding a \"None\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "Clean comments using techniques from other kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_train_df = pd.read_csv(f'{PATH}/train.csv')\n",
    "test_df = pd.read_csv(f'{PATH}/test.csv')\n",
    "sample_subm_df = pd.read_csv(f'{PATH}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "raw_train_df['none'] = 1 - raw_train_df[label_cols].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_train_df.comment_text.fillna(\"<na>\", inplace=True)\n",
    "test_df.comment_text.fillna(\"<na>\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     83
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repl = {\n",
    "    \"&lt;3\": \" good \",\n",
    "    \":d\": \" good \",\n",
    "    \":dd\": \" good \",\n",
    "    \":p\": \" good \",\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":s\": \" bad \",\n",
    "    \":-s\": \" bad \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "    r\"\\bi'm\\b\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"r\": \"are\",\n",
    "    \"u\": \"you\",\n",
    "    \"haha\": \"ha\",\n",
    "    \"hahaha\": \"ha\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"its\" : \"it is\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"'s\" : \" is\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"weren't\" : \"were not\",\n",
    "}\n",
    "\n",
    "#https://drive.google.com/file/d/0B1yuv8YaUVlZZ1RzMFJmc1ZsQmM/view\n",
    "# Aphost lookup dict\n",
    "appos = {\n",
    "    \"aren't\" : \"are not\",\n",
    "    \"can't\" : \"cannot\",\n",
    "    \"couldn't\" : \"could not\",\n",
    "    \"didn't\" : \"did not\",\n",
    "    \"doesn't\" : \"does not\",\n",
    "    \"don't\" : \"do not\",\n",
    "    \"hadn't\" : \"had not\",\n",
    "    \"hasn't\" : \"has not\",\n",
    "    \"haven't\" : \"have not\",\n",
    "    \"he'd\" : \"he would\",\n",
    "    \"he'll\" : \"he will\",\n",
    "    \"he's\" : \"he is\",\n",
    "    \"i'd\" : \"I would\",\n",
    "    \"i'd\" : \"I had\",\n",
    "    \"i'll\" : \"I will\",\n",
    "    \"i'm\" : \"I am\",\n",
    "    \"isn't\" : \"is not\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"it'll\":\"it will\",\n",
    "    \"i've\" : \"I have\",\n",
    "    \"let's\" : \"let us\",\n",
    "    \"mightn't\" : \"might not\",\n",
    "    \"mustn't\" : \"must not\",\n",
    "    \"shan't\" : \"shall not\",\n",
    "    \"she'd\" : \"she would\",\n",
    "    \"she'll\" : \"she will\",\n",
    "    \"she's\" : \"she is\",\n",
    "    \"shouldn't\" : \"should not\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"there's\" : \"there is\",\n",
    "    \"they'd\" : \"they would\",\n",
    "    \"they'll\" : \"they will\",\n",
    "    \"they're\" : \"they are\",\n",
    "    \"they've\" : \"they have\",\n",
    "    \"we'd\" : \"we would\",\n",
    "    \"we're\" : \"we are\",\n",
    "    \"weren't\" : \"were not\",\n",
    "    \"we've\" : \"we have\",\n",
    "    \"what'll\" : \"what will\",\n",
    "    \"what're\" : \"what are\",\n",
    "    \"what's\" : \"what is\",\n",
    "    \"what've\" : \"what have\",\n",
    "    \"where's\" : \"where is\",\n",
    "    \"who'd\" : \"who would\",\n",
    "    \"who'll\" : \"who will\",\n",
    "    \"who're\" : \"who are\",\n",
    "    \"who's\" : \"who is\",\n",
    "    \"who've\" : \"who have\",\n",
    "    \"won't\" : \"will not\",\n",
    "    \"wouldn't\" : \"would not\",\n",
    "    \"you'd\" : \"you would\",\n",
    "    \"you'll\" : \"you will\",\n",
    "    \"you're\" : \"you are\",\n",
    "    \"you've\" : \"you have\",\n",
    "    \"'re\": \" are\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'll\":\" will\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"tryin'\": \"trying\"\n",
    "}\n",
    "\n",
    "repl = { **appos, **repl }  # repl becomes a merged dictionary with values from repl replacing those from appos\n",
    "\n",
    "# display(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "repl_keys = [i for i in repl.keys()]\n",
    "\n",
    "def clean(comment):\n",
    "    # convert to lower case , so that Hi and hi are the same\n",
    "    comment = comment.lower()\n",
    "    \n",
    "    # remove \\n \n",
    "    # torchtext cannot read the .csv files correctly if there are newline characters, so replace with \" \"\n",
    "    comment = re.sub(\"\\\\n\",\" \",comment)\n",
    "    \n",
    "    # remove leaky elements like ip,user\n",
    "    comment = re.sub(\"\\d{1,3}.\\d{1,3}.\\d{1,3}.\\d{1,3}\",\" \",comment)\n",
    "    \n",
    "    # removing usernames\n",
    "    comment = re.sub(\"\\[\\[.*\\]\",\"\",comment)\n",
    "    \n",
    "    # do any substitutions\n",
    "    comment = \" \".join([ repl[w] if (w in repl_keys) else w for w in comment.split() ])\n",
    "    \n",
    "    return(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%time raw_train_df['comment_text_cleaned'] = raw_train_df.comment_text.apply(lambda x: clean(x))\n",
    "print('train cleaned ...')\n",
    "\n",
    "%time test_df['comment_text_cleaned'] = test_df.comment_text.apply(lambda x: clean(x))\n",
    "print('test cleaned ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_train_df.to_csv(f'{PATH}/train_preproc.csv', index=None)\n",
    "test_df.to_csv(f'{PATH}/test_preproc.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Used the preprocessed datasets for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_train_df = pd.read_csv(f'{PATH}/train_preproc.csv')\n",
    "test_df = pd.read_csv(f'{PATH}/test_preproc.csv')\n",
    "sample_subm_df = pd.read_csv(f'{PATH}/sample_submission.csv')\n",
    "\n",
    "txt_col = 'comment_text_cleaned'\n",
    "\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "raw_train_df['none'] = 1 - raw_train_df[label_cols].max(axis=1)\n",
    "\n",
    "model_cols = ['id', txt_col] + label_cols + ['none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "n_trn = len(raw_train_df)\n",
    "n_examples_per_fold = n_trn // n_folds\n",
    "\n",
    "# n_examples_per_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prepare Data\n",
    "\n",
    "*Note: Only need to run 1x (or as desired to regenerate these .csv files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Build cross-validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_train_df_rand = raw_train_df.sample(frac=1, random_state=9) # frac=1 = return all rows in random order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_dfs = []\n",
    "\n",
    "for i in range(0, n_folds):\n",
    "    start = i * n_examples_per_fold\n",
    "    end = n_examples_per_fold + start if (i + 1 < n_folds) else None\n",
    "    val_dfs.append(raw_train_df_rand[start:end])\n",
    "    \n",
    "# [ print(idx,len(d)) for idx, d in enumerate(val_dfs) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_dfs = []\n",
    "\n",
    "for idx, df in enumerate(val_dfs):\n",
    "    trn_dfs.append(pd.concat([ val_df for val_idx, val_df in enumerate(val_dfs) if val_idx != idx]))\n",
    "    \n",
    "# [ print(idx,len(d)) for idx, d in enumerate(trn_dfs) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 143614 15957\n",
      "1 143614 15957\n",
      "2 143614 15957\n",
      "3 143614 15957\n",
      "4 143614 15957\n",
      "5 143614 15957\n",
      "6 143614 15957\n",
      "7 143614 15957\n",
      "8 143614 15957\n",
      "9 143613 15958\n"
     ]
    }
   ],
   "source": [
    "for idx, [trn_df, val_df] in enumerate(zip(trn_dfs, val_dfs)):\n",
    "    print(idx, len(trn_df), len(val_df))\n",
    "    \n",
    "    trn_df[model_cols].to_csv(f'{PATH}/train_ds_{idx}_of_{n_folds}.csv', index=None)\n",
    "    val_df[model_cols].to_csv(f'{PATH}/valid_ds_{idx}_of_{n_folds}.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use the below if you want to create a single training and cv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91058 4793 9288 502\n"
     ]
    }
   ],
   "source": [
    "# split the training data into a train and validatin dataset\n",
    "trn, val = train_test_split(raw_train_df, test_size=0.05, random_state=9)\n",
    "print(len(trn), len(val), len(trn[trn.none != 1]), len(val[val.none != 1]))\n",
    "\n",
    "# save train, val, and test datasets for torchtext\n",
    "trn[model_cols].to_csv(f'{PATH}/train_ds.csv', index=None)\n",
    "val[model_cols].to_csv(f'{PATH}/valid_ds.csv', index=None)\n",
    "\n",
    "# save full cleaned datasets (train+valid and test) as well\n",
    "raw_train_df[model_cols].to_csv(f'{PATH}/full_train_ds.csv', index=None)\n",
    "test_df[['id', txt_col]].to_csv(f'{PATH}/test_ds.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text_cleaned</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22256635</td>\n",
       "      <td>nonsense? kiss off, geek. what i said is true. i will have your account terminated.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27450690</td>\n",
       "      <td>\" please do not vandalize pages, as you did with this edit to w. s. merwin. if you continue to do so, you will be blocked from editing. \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0  22256635   \n",
       "1  27450690   \n",
       "\n",
       "                                                                                                                        comment_text_cleaned  \\\n",
       "0  nonsense? kiss off, geek. what i said is true. i will have your account terminated.                                                         \n",
       "1  \" please do not vandalize pages, as you did with this edit to w. s. merwin. if you continue to do so, you will be blocked from editing. \"   \n",
       "\n",
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  none  \n",
       "0  1      0             0        0       0       0              0     \n",
       "1  0      0             0        0       0       0              1     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6044863</td>\n",
       "      <td>==orphaned non-free media (image:41cd1jboevl. ss500 .jpg)==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6102620</td>\n",
       "      <td>::kentuckiana is colloquial. even though the area is often referred to as this, it (in my opinion) has never held the encyclopedic precision of \"louisville metropolitian area\", which has a specific u.s. census definition. also, apparently kentuckiana often refers to the local television viewing area, which is not nearly contiguous with the official metro area. as you indicate, kentuckiana seems to be more of a slang or marketing phenomena than anything we could pin down in encyclopedic terms here. that is why we see wikipedia language like \"the louisville metropolitan area, sometimes referred to as kentuckiana\". that is my take on it. — •</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  6044863   \n",
       "1  6102620   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     comment_text_cleaned  \n",
       "0  ==orphaned non-free media (image:41cd1jboevl. ss500 .jpg)==                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "1  ::kentuckiana is colloquial. even though the area is often referred to as this, it (in my opinion) has never held the encyclopedic precision of \"louisville metropolitian area\", which has a specific u.s. census definition. also, apparently kentuckiana often refers to the local television viewing area, which is not nearly contiguous with the official metro area. as you indicate, kentuckiana seems to be more of a slang or marketing phenomena than anything we could pin down in encyclopedic terms here. that is why we see wikipedia language like \"the louisville metropolitan area, sometimes referred to as kentuckiana\". that is my take on it. — •  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.read_csv(\"data/full_train_ds.csv\").head(2))\n",
    "display(pd.read_csv(\"data/test_ds.csv\").head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build Datasets and DataLoaders\n",
    "\n",
    "Define hyperparameters and column that holds text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_features = 100000 #30000\n",
    "min_freq = 10 #0\n",
    "max_len = 175 #100\n",
    "\n",
    "pretrained_vectors = None #'fasttext.en.300d'\n",
    "\n",
    "batch_sizes = (64,64,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Configure how we are going to process text and label fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TEXT_fld = data.Field(sequential=True, tokenize=tokenize, lower=True, fix_length=max_len)\n",
    "LABEL_fld = data.Field(sequential=False, use_vocab=False, tensor_type=torch.cuda.ByteTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are various built-in Datasets in torchtext that handle common use cases. **For csv/tsv files, the TabularDataset class** is convenient. Here’s how we would read data from a csv file using the TabularDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 s, sys: 6.56 s, total: 40.4 s\n",
      "Wall time: 40.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# train/validation\n",
    "train_datafields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                    (txt_col, TEXT_fld),\n",
    "                    (\"toxic\", LABEL_fld), (\"severe_toxic\", LABEL_fld), (\"obscene\", LABEL_fld),\n",
    "                    (\"threat\", LABEL_fld), (\"insult\", LABEL_fld), (\"identity_hate\", LABEL_fld), (\"none\", None)]\n",
    "\n",
    "train_ds, valid_ds = data.TabularDataset.splits(PATH, train='train_ds.csv', validation='valid_ds.csv',\n",
    "                                          format='csv', skip_header=True, fields=train_datafields)\n",
    "\n",
    "# test\n",
    "test_datafields = [(\"id\", None), (txt_col, TEXT_fld)]\n",
    "test_ds = data.TabularDataset(f'{PATH}/test_ds.csv', format='csv', skip_header=True, fields=test_datafields)\n",
    "\n",
    "# train+val\n",
    "full_train_ds = data.TabularDataset(f'{PATH}/full_train_ds.csv', \n",
    "                                    format='csv', skip_header=True, fields=train_datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.example.Example at 0x1cca16d7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['comment_text_cleaned', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['\"', 'i', 'appreciate', 'your', 'intention']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_ds[0])\n",
    "display(train_ds[0].__dict__.keys())\n",
    "display(train_ds[1].comment_text_cleaned[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Build vocab on *full* training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TEXT_fld.build_vocab(full_train_ds, min_freq=min_freq, max_size=max_features, vectors=pretrained_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 389774),\n",
       " ('the', 298502),\n",
       " (',', 284449),\n",
       " ('\"', 234054),\n",
       " ('to', 178418),\n",
       " ('i', 144135),\n",
       " ('of', 135293),\n",
       " ('you', 134659),\n",
       " ('and', 134609),\n",
       " ('is', 133857)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The vocab.freqs is a collections.Counter object, so we can take a look at the most frequent words.\n",
    "TEXT_fld.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits(\n",
    "    (train_ds, valid_ds), # we pass in the datasets we want the iterator to draw data from\n",
    "    batch_sizes=(batch_sizes[0], batch_sizes[1]),\n",
    "    device=0, #-1 if CPU else GPU number if you want to use the GPU\n",
    "    sort_key=lambda x: len(x.comment_text_cleaned), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "    sort_within_batch=False,\n",
    "    repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.batch.Batch at 0x1c2140c208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['batch_size', 'dataset', 'train', 'comment_text_cleaned', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(train_iter.__iter__()); \n",
    "\n",
    "display(batch)\n",
    "display(batch.__dict__.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the test set, we don't want the data to be shuffled. This is why we'll be using a standard Iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_iter = data.Iterator(test_ds, batch_size=batch_sizes[2], device=0, train=False, \n",
    "                          shuffle=False, sort=False, sort_within_batch=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "        self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            if self.y_vars is not None: # we will concatenate y into a single tensor\n",
    "                y = torch.cat([ getattr(batch, feat).unsqueeze(1) for feat in self.y_vars ], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, txt_col, label_cols)\n",
    "valid_dl = BatchWrapper(val_iter, txt_col, label_cols)\n",
    "test_dl = BatchWrapper(test_iter, txt_col, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Construct a fastai ModelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "md = ModelData(PATH, trn_dl=train_dl, val_dl=valid_dl, test_dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "      9    141    680  ...    8263  19180   1134\n",
       "    220      9      2  ...      58     88     31\n",
       "    233     18      9  ...      43    187    364\n",
       "         ...            ⋱           ...         \n",
       "      1      1      1  ...       1      1      1\n",
       "      1      1      1  ...       1      1      1\n",
       "      1      1      1  ...       1      1      1\n",
       " [torch.LongTensor of size 175x64], Variable containing:\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     1     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     1     1     1     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     0     0     0\n",
       "     1     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     1     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       " [torch.FloatTensor of size 64x6])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Define Models\n",
    "\n",
    "Define a simple GRU and a simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimpleGru(nn.Module):\n",
    "    def __init__(self, vocab_sz, emb_sz=300, n_rnn_hidden=256, n_rnn_layers=1, bi_dir=True, out_sz=1, bsz=64,\n",
    "                 dropout_rnn=0.3, dropout_after_emb=0.4, dropout_emb=0.1, wdrop=0.05):\n",
    "        \n",
    "        super().__init__() \n",
    "        \n",
    "        self.bsz = bsz\n",
    "               \n",
    "        # configure embeddings layer\n",
    "        self.dropout_emb = dropout_emb\n",
    "        self.dropout_after_emb = LockedDropout(dropout_after_emb)\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_sz, emb_sz)\n",
    "        self.emb.data = train_ds.fields[txt_col].vocab.vectors # to use the pretrained vectors\n",
    "        self.emb_with_drop = EmbeddingDropout(self.emb)\n",
    "        \n",
    "        # configure rnns\n",
    "        self.n_rnn_hidden, self.n_rnn_layers, self.n_dirs = n_rnn_hidden, n_rnn_layers, 2 if bi_dir else 1\n",
    "        self.rnn = nn.GRU(emb_sz, self.n_rnn_hidden, self.n_rnn_layers, bidirectional=bi_dir, dropout=dropout_rnn)\n",
    "        if wdrop: self.rnn = WeightDrop(self.rnn, wdrop)\n",
    "      \n",
    "        self.outp = nn.Linear(n_rnn_hidden * 2 * self.n_dirs, out_sz)\n",
    "        \n",
    "        # initialize weights\n",
    "        kaiming_normal(self.outp.weight.data)\n",
    "        \n",
    "        # init hidden\n",
    "        self.init_hidden(self.bsz)\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        bsz = seq.size(1)\n",
    "        if (self.hidden[0].size(1) != bsz): self.init_hidden(bsz)\n",
    "        \n",
    "        x = self.emb_with_drop(seq, dropout=self.dropout_emb if self.training else 0)\n",
    "        x = self.dropout_after_emb(x)\n",
    "        \n",
    "        output, h = self.rnn(x, self.hidden)        \n",
    "        self.hidden = repackage_var(h)\n",
    "        \n",
    "        sl, bs, _ = output.size()\n",
    "  \n",
    "        avg_pool = F.adaptive_avg_pool1d(output.permute(1,2,0), (1,)).view(bs,-1)   \n",
    "        max_pool = F.adaptive_max_pool1d(output.permute(1,2,0), (1,)).view(bs,-1) \n",
    "        \n",
    "        x = torch.cat([avg_pool, max_pool], dim=1)\n",
    "        outp = F.sigmoid(self.outp(x))\n",
    "        \n",
    "        return outp\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        self.hidden = V(torch.zeros(self.n_dirs * self.n_rnn_layers, bsz, self.n_rnn_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimpleLstm(nn.Module):\n",
    "    def __init__(self, vocab_sz, emb_sz=300, n_rnn_hidden=256, n_rnn_layers=1, bi_dir=True, out_sz=1, bsz=64,\n",
    "                 dropout_rnn=0.3, dropout_after_emb=0.4, dropout_emb=0.1, wdrop=0.05):\n",
    "        \n",
    "        super().__init__() \n",
    "        \n",
    "        self.bsz = bsz\n",
    "               \n",
    "        # configure embeddings layer\n",
    "        self.dropout_emb = dropout_emb\n",
    "        self.dropout_after_emb = LockedDropout(dropout_after_emb)\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_sz, emb_sz)\n",
    "        self.emb.data = train_ds.fields[txt_col].vocab.vectors # to use the pretrained vectors\n",
    "        self.emb_with_drop = EmbeddingDropout(self.emb)\n",
    "        \n",
    "        # configure rnns\n",
    "        self.n_rnn_hidden, self.n_rnn_layers, self.n_dirs = n_rnn_hidden, n_rnn_layers, 2 if bi_dir else 1\n",
    "        self.rnn = nn.LSTM(emb_sz, self.n_rnn_hidden, self.n_rnn_layers, bidirectional=bi_dir, dropout=dropout_rnn)\n",
    "        if wdrop: self.rnn = WeightDrop(self.rnn, wdrop)\n",
    "      \n",
    "        self.outp = nn.Linear(n_rnn_hidden * 2 * self.n_dirs, out_sz)\n",
    "        \n",
    "        # initialize weights\n",
    "        kaiming_normal(self.outp.weight.data)\n",
    "        \n",
    "        # init hidden\n",
    "        self.init_hidden(self.bsz)\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        bsz = seq.size(1)\n",
    "        if (self.hidden[0].size(1) != bsz): self.init_hidden(bsz)\n",
    "        \n",
    "        x = self.emb_with_drop(seq, dropout=self.dropout_emb if self.training else 0)\n",
    "        x = self.dropout_after_emb(x)\n",
    "        \n",
    "        output, h = self.rnn(x, self.hidden)        \n",
    "        self.hidden = repackage_var(h)\n",
    "        \n",
    "        sl, bs, _ = output.size()\n",
    "  \n",
    "        avg_pool = F.adaptive_avg_pool1d(output.permute(1,2,0), (1,)).view(bs,-1)   \n",
    "        max_pool = F.adaptive_max_pool1d(output.permute(1,2,0), (1,)).view(bs,-1) \n",
    "        \n",
    "        x = torch.cat([avg_pool, max_pool], dim=1)\n",
    "        outp = F.sigmoid(self.outp(x))\n",
    "        \n",
    "        return outp\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        self.hidden = (V(torch.zeros(self.n_dirs * self.n_rnn_layers, bsz, self.n_rnn_hidden)),\n",
    "                       V(torch.zeros(self.n_dirs * self.n_rnn_layers, bsz, self.n_rnn_hidden)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Instantiate a `SimpleLstm` model, experimenting with various hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLstm(\n",
       "  (dropouti): LockedDropout(\n",
       "  )\n",
       "  (emb): Embedding(26970, 300)\n",
       "  (emb_with_drop): EmbeddingDropout(\n",
       "    (embed): Embedding(26970, 300)\n",
       "  )\n",
       "  (rnn): WeightDrop(\n",
       "    (module): LSTM(300, 128, dropout=0.3, bidirectional=True)\n",
       "  )\n",
       "  (linears): ModuleList(\n",
       "  )\n",
       "  (linear_bns): ModuleList(\n",
       "  )\n",
       "  (linear_drops): ModuleList(\n",
       "  )\n",
       "  (outp): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_sz = len(TEXT_fld.vocab)\n",
    "emb_sz = 300\n",
    "out_sz = 6\n",
    "\n",
    "n_rnn_hidden = 128\n",
    "n_rnn_layers = 1\n",
    "bi_dir = True\n",
    "\n",
    "model = SimpleLstm(vocab_sz, emb_sz, n_rnn_hidden, n_rnn_layers, True, out_sz, bsz=batch_sizes[0])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train Model\n",
    "\n",
    "Utilize fastai callbacks to add weight-decay and SGDR with restarts goodness.  You can experiment with other callbacks here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lo = LayerOptimizer(optim.Adam, model, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(model, f'{PATH}/models/lstm_fit_1_cyc_{cycle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Utilize the fastai `fit()` method to train the model.  This is our training/validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a36faa86214cd7be0b4a4fd8c561d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2369 [00:00<14:12,  2.78it/s, loss=0.752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      0.051143   0.045428  \n",
      "    1      0.052452   0.048086                                  \n",
      "    2      0.048935   0.042793                                  \n",
      "    3      0.057762   0.053487                                  \n",
      "    4      0.050881   0.046729                                  \n",
      "    5      0.049764   0.043361                                  \n",
      "    6      0.045766   0.041723                                  \n",
      "    7      0.060439   0.052335                                  \n",
      "    8      0.060282   0.052392                                  \n",
      "    9      0.061376   0.049558                                  \n",
      "    10     0.052035   0.045024                                  \n",
      "    11     0.050743   0.045635                                  \n",
      "    12     0.050397   0.042907                                  \n",
      "    13     0.045974   0.042163                                  \n",
      "    14     0.04428    0.042109                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.042109344]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 2**4-1, lo.opt, F.binary_cross_entropy, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{PATH}/models/lstm_fit_1_cyc_3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf11421e2e4e46f5a45c9775b4a83729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2369 [00:00<12:26,  3.17it/s, loss=0.0313]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      0.047446   0.042326  \n",
      "    1      0.060109   0.052738                                  \n",
      "    2      0.061474   0.052812                                  \n",
      "    3      0.052966   0.051033                                  \n",
      "    4      0.053826   0.052875                                  \n",
      "    5      0.052001   0.048456                                  \n",
      "    6      0.056809   0.048939                                  \n",
      "    7      0.058547   0.049012                                  \n",
      "    8      0.055328   0.045812                                  \n",
      "    9      0.053131   0.04595                                   \n",
      "    10     0.053966   0.045393                                  \n",
      "    11     0.051473   0.045612                                  \n",
      "    12     0.047847   0.046206                                  \n",
      "    13     0.051698   0.043556                                  \n",
      "    14     0.048082   0.043449                                  \n",
      "    15     0.043666   0.042684                                  \n",
      "    16     0.045495   0.041769                                  \n",
      "    17     0.045065   0.041702                                  \n",
      "    18     0.043052   0.041511                                  \n",
      "    19     0.039245   0.041532                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.041532446]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(model, f'{PATH}/models/lstm_fit_2_cyc_{cycle}')\n",
    "\n",
    "lo = LayerOptimizer(optim.Adam, model, 1e-2, 1e-5)\n",
    "cb = [CosAnneal(lo, (len(md.trn_dl) * 20), on_cycle_end=on_end)]\n",
    "\n",
    "fit(model, md, 20, lo.opt, F.binary_cross_entropy, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict(model, test_dl)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.333234</td>\n",
       "      <td>0.969354</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>0.945446</td>\n",
       "      <td>0.271051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is, IMO.</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  00001cee341fdb12   \n",
       "1  0000247867823ef7   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      comment_text  \\\n",
       "0  Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,   \n",
       "1  == From RfC == \\n\\n The title is fine as it is, IMO.                                                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "      toxic  severe_toxic   obscene    threat    insult  identity_hate  \n",
       "0  0.998924  0.333234      0.969354  0.054596  0.945446  0.271051       \n",
       "1  0.002046  0.000065      0.000780  0.000029  0.000780  0.000138       "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_df = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "for i, col in enumerate([\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]):\n",
    "    subm_df[col] = preds[:, i]\n",
    "\n",
    "subm_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if you want to write the submission file to disk, uncomment and run the below code\n",
    "subm_df.drop(['comment_text'], axis=1).to_csv(f'{PATH}/submissions/lstm_subm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## K-Fold Cross Validation\n",
    "\n",
    "We can perform a k-fold cross validation by following the same steps on the base training/validation datasets, except this time we use the CV training/validation datasets we created up top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Fold 0 ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8352fdffe6f46fab1d5a76f2fa9fb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2244 [00:00<12:44,  2.93it/s, loss=0.593]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  result = self.forward(*input, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      0.045258   0.046109  \n",
      "    1      0.058406   0.049222                                  \n",
      "    2      0.049904   0.042761                                  \n",
      "    3      0.056364   0.061599                                  \n",
      "    4      0.052477   0.047066                                  \n",
      "    5      0.050293   0.042976                                  \n",
      "    6      0.042117   0.041887                                  \n",
      "    7      0.053778   0.058154                                  \n",
      "    8      0.057674   0.052213                                  \n",
      "    9      0.056211   0.047922                                  \n",
      "    10     0.049906   0.046597                                  \n",
      "    11     0.050576   0.045229                                  \n",
      "    12     0.05148    0.0425                                    \n",
      "    13     0.045406   0.041833                                  \n",
      "    14     0.04314    0.041853                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e8214975aa4c7ea66d28b1b0627933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.04807    0.042009  \n",
      "    1      0.043071   0.042385                                  \n",
      "    2      0.041938   0.041669                                  \n",
      "    3      0.039948   0.041536                                  \n",
      "    4      0.040798   0.041548                                  \n",
      "    5      0.041751   0.04168                                   \n",
      "\n",
      "----------\n",
      "Fold 1 ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5bc1638e7941799e4887aa90fbeed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.0469     0.044532  \n",
      "    1      0.053637   0.046548                                  \n",
      "    2      0.04584    0.041699                                  \n",
      "    3      0.055985   0.052053                                  \n",
      "    4      0.052709   0.048491                                  \n",
      "    5      0.047826   0.042662                                  \n",
      "    6      0.042924   0.041063                                  \n",
      "    7      0.056542   0.052626                                  \n",
      "    8      0.057511   0.049231                                  \n",
      "    9      0.055543   0.048936                                  \n",
      "    10     0.052002   0.045256                                  \n",
      "    11     0.052559   0.043447                                  \n",
      "    12     0.050953   0.042409                                  \n",
      "    13     0.046146   0.04074                                   \n",
      "    14     0.042522   0.040535                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a47c32abe1f4b8fbf4dd497ab778d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.048078   0.041007  \n",
      "    1      0.044074   0.040757                                  \n",
      "    2      0.041425   0.040185                                  \n",
      "    3      0.039798   0.040258                                  \n",
      "    4      0.040758   0.04013                                   \n",
      "    5      0.04134    0.040319                                  \n",
      "\n",
      "----------\n",
      "Fold 2 ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0a00157e6a4b21888701eb73caea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.046211   0.046232  \n",
      "    1      0.054699   0.049172                                  \n",
      "    2      0.047717   0.043116                                  \n",
      "    3      0.056392   0.0542                                    \n",
      "    4      0.050505   0.051808                                  \n",
      "    5      0.050483   0.046325                                  \n",
      "    6      0.04397    0.042497                                  \n",
      "    7      0.057687   0.052988                                  \n",
      "    8      0.057719   0.052651                                  \n",
      "    9      0.05681    0.05001                                   \n",
      "    10     0.051583   0.045737                                  \n",
      "    11     0.050292   0.046601                                  \n",
      "    12     0.04866    0.043947                                  \n",
      "    13     0.047621   0.04177                                   \n",
      "    14     0.038589   0.041778                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4036b17a3694aa6a89a91d1ef3eae9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.047435   0.042207  \n",
      "    1      0.044574   0.04222                                   \n",
      "    2      0.041033   0.04163                                   \n",
      "    3      0.041096   0.041483                                  \n",
      "    4      0.038985   0.041551                                  \n",
      "    5      0.039009   0.041655                                  \n",
      "\n",
      "----------\n",
      "Fold 3 ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3370ab752843fb95f433e26c34549b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.045842   0.044461  \n",
      "    1      0.054112   0.046143                                  \n",
      "    2      0.045601   0.041891                                  \n",
      "    3      0.057592   0.055015                                  \n",
      "    4      0.048375   0.047729                                  \n",
      "    5      0.048961   0.042708                                  \n",
      "    6      0.043502   0.041123                                  \n",
      "    7      0.058658   0.050482                                  \n",
      "    8      0.056168   0.059926                                  \n",
      "    9      0.05659    0.048221                                  \n",
      "    10     0.050267   0.045249                                  \n",
      "    11     0.052742   0.044252                                  \n",
      "    12     0.047401   0.041722                                  \n",
      "    13     0.047722   0.040836                                  \n",
      "    14     0.039114   0.04065                                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3645b2f302da4e648052768e05d32917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.048837   0.041079  \n",
      "    1      0.043232   0.04098                                   \n",
      "    2      0.042975   0.040517                                  \n",
      "    3      0.043268   0.040325                                  \n",
      "    4      0.039741   0.040574                                  \n",
      "    5      0.038668   0.040645                                  \n",
      "\n",
      "----------\n",
      "Fold 4 ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b72659a59549cbac24d250e18fae23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.047394   0.044547  \n",
      "    1      0.054482   0.047049                                  \n",
      "    2      0.043276   0.04153                                   \n",
      "    3      0.056433   0.051465                                  \n",
      "    4      0.04939    0.048894                                  \n",
      "    5      0.047884   0.042169                                  \n",
      "    6      0.044711   0.040562                                  \n",
      "    7      0.059609   0.051617                                  \n",
      "    8      0.052984   0.052207                                  \n",
      "    9      0.054231   0.047272                                  \n",
      "    10     0.051272   0.045369                                  \n",
      "    11     0.05297    0.043546                                  \n",
      "    12     0.048185   0.041898                                  \n",
      "    13     0.048386   0.040756                                  \n",
      "    14     0.040677   0.040414                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da07ef137dd449939fbc2f053a942976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.045067   0.040743  \n",
      "    1      0.042674   0.040583                                  \n",
      "    2      0.038848   0.040784                                  \n",
      "    3      0.040375   0.040044                                  \n",
      "    4      0.04045    0.040178                                  \n",
      "    5      0.036137   0.040224                                  \n",
      "\n",
      "----------\n",
      "Fold 5 ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6e1fc1c3ff489d9945b175dea0315a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.046817   0.047256  \n",
      "    1      0.054021   0.050298                                  \n",
      "    2      0.044163   0.043861                                  \n",
      "    3      0.054303   0.052147                                  \n",
      "    4      0.051907   0.04782                                   \n",
      "    5      0.04641    0.044826                                  \n",
      "    6      0.045651   0.04293                                   \n",
      "    7      0.055372   0.05412                                   \n",
      "    8      0.056726   0.059057                                  \n",
      "    9      0.053099   0.050688                                  \n",
      "    10     0.053554   0.047085                                  \n",
      "    11     0.051476   0.045464                                  \n",
      "    12     0.049338   0.043688                                  \n",
      "    13     0.045399   0.042582                                  \n",
      "    14     0.041039   0.042308                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f473498961fa423b820d594dcad8cf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.045243   0.043258  \n",
      "    1      0.040643   0.042408                                  \n",
      "    2      0.039267   0.042547                                  \n",
      "    3      0.040848   0.042014                                  \n",
      "    4      0.040975   0.041901                                  \n",
      "    5      0.036123   0.042103                                  \n",
      "\n",
      "----------\n",
      "Fold 6 ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d25d1590e04d9ab5df915c414b84dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.048828   0.044603  \n",
      "    1      0.057639   0.047223                                  \n",
      "    2      0.045096   0.04174                                   \n",
      "    3      0.056414   0.050528                                  \n",
      "    4      0.050524   0.046926                                  \n",
      "    5      0.044799   0.042479                                  \n",
      "    6      0.043476   0.040853                                  \n",
      "    7      0.228312   0.215125                                 \n",
      "    8      0.18473    0.175434                                 \n",
      "    9      0.191839   0.17328                                  \n",
      "    10     0.163559   0.171044                                 \n",
      "    11     0.131054   0.117068                                 \n",
      "    12     0.129085   0.117278                                 \n",
      "    13     0.129815   0.113865                                 \n",
      "    14     0.125669   0.113395                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a20bb0780bc48ffb3dc2e46498d9c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                 \n",
      "    0      0.132102   0.113707  \n",
      "    1      0.113833   0.112545                                 \n",
      "    2      0.120266   0.113575                                 \n",
      "    3      0.123676   0.112638                                 \n",
      "    4      0.12268    0.112613                                 \n",
      "    5      0.122679   0.112709                                 \n",
      "\n",
      "----------\n",
      "Fold 7 ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7aa87db6fee4a808248b91ad8b350c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.047827   0.045387  \n",
      "    1      0.058011   0.047186                                  \n",
      "    2      0.044898   0.042663                                  \n",
      "    3      0.056477   0.057776                                  \n",
      "    4      0.049528   0.047493                                  \n",
      "    5      0.048635   0.043087                                  \n",
      "    6      0.043139   0.041725                                  \n",
      "    7      0.064508   0.059641                                  \n",
      "    8      0.060508   0.052746                                  \n",
      "    9      0.054367   0.04921                                   \n",
      "    10     0.050875   0.046835                                  \n",
      "    11     0.050711   0.045438                                  \n",
      "    12     0.048188   0.042555                                  \n",
      "    13     0.049447   0.041567                                  \n",
      "    14     0.042334   0.041672                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06edb4d50ed4472ab607bb030a989259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.044745   0.042613  \n",
      "    1      0.041323   0.041684                                  \n",
      "    2      0.041905   0.041561                                  \n",
      "    3      0.041196   0.040889                                  \n",
      "    4      0.040183   0.041134                                  \n",
      "    5      0.038006   0.041314                                  \n",
      "\n",
      "----------\n",
      "Fold 8 ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b82844ad974d389efc9e21a0dbd164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.047918   0.047084  \n",
      "    1      0.059236   0.053703                                  \n",
      "    2      0.044655   0.044367                                  \n",
      "    3      0.057386   0.054183                                  \n",
      "    4      0.048193   0.049964                                  \n",
      "    5      0.044946   0.046543                                  \n",
      "    6      0.045924   0.04411                                   \n",
      "    7      0.058995   0.055836                                  \n",
      "    8      0.058722   0.052898                                  \n",
      "    9      0.054531   0.052112                                  \n",
      "    10     0.052147   0.048714                                  \n",
      "    11     0.049246   0.045724                                  \n",
      "    12     0.049708   0.044345                                  \n",
      "    13     0.043683   0.043433                                  \n",
      "    14     0.041986   0.04353                                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb02c9d06444aeea563e7cc95bba041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.044418   0.044448  \n",
      "    1      0.03985    0.043705                                  \n",
      "    2      0.039774   0.044234                                  \n",
      "    3      0.041095   0.043214                                  \n",
      "    4      0.039615   0.043575                                  \n",
      "    5      0.036174   0.043688                                  \n",
      "\n",
      "----------\n",
      "Fold 9 ....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb35170190b483c8e361fb4f2398612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.048021   0.047052  \n",
      "    1      0.056743   0.048223                                  \n",
      "    2      0.044408   0.04363                                   \n",
      "    3      0.057738   0.051385                                  \n",
      "    4      0.051514   0.048031                                  \n",
      "    5      0.048279   0.044213                                  \n",
      "    6      0.045182   0.042637                                  \n",
      "    7      0.064643   0.067792                                  \n",
      "    8      0.056401   0.051193                                  \n",
      "    9      0.057105   0.049551                                  \n",
      "    10     0.052294   0.050228                                  \n",
      "    11     0.05034    0.045985                                  \n",
      "    12     0.047373   0.044812                                  \n",
      "    13     0.044682   0.042055                                  \n",
      "    14     0.040304   0.042011                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91364932a8c4a4fa2c8f2baddc22b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.042868   0.042617  \n",
      "    1      0.040834   0.042033                                  \n",
      "    2      0.041524   0.042581                                  \n",
      "    3      0.038731   0.041987                                  \n",
      "    4      0.0412     0.041493                                  \n",
      "    5      0.037848   0.041736                                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_datafields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                    (txt_col, TEXT_fld),\n",
    "                    (\"toxic\", LABEL_fld), (\"severe_toxic\", LABEL_fld), (\"obscene\", LABEL_fld),\n",
    "                    (\"threat\", LABEL_fld), (\"insult\", LABEL_fld), (\"identity_hate\", LABEL_fld), (\"none\", None)]\n",
    "\n",
    "# test\n",
    "test_datafields = [(\"id\", None), (txt_col, TEXT_fld)]\n",
    "\n",
    "# define test dataset and iterator\n",
    "test_ds = data.TabularDataset(f'{PATH}/test_ds.csv', format='csv', skip_header=True, fields=test_datafields)\n",
    "test_iter = data.Iterator(test_ds, batch_size=batch_sizes[2], device=0, train=False, \n",
    "                          shuffle=False, sort=False, sort_within_batch=False, repeat=False)\n",
    "test_dl = BatchWrapper(test_iter, txt_col, None)\n",
    "\n",
    "# define FULL train dataset for building vocab\n",
    "full_train_ds = data.TabularDataset(f'{PATH}/full_train_ds.csv', \n",
    "                                    format='csv', skip_header=True, fields=train_datafields)\n",
    "\n",
    "TEXT_fld.build_vocab(full_train_ds, min_freq=min_freq, max_size=max_features, vectors=pretrained_vectors)\n",
    "\n",
    "# cv\n",
    "for i in range(n_folds):\n",
    "    print('-' * 10)\n",
    "    print(f'Fold {i} ....')\n",
    "    \n",
    "    # train/validation datsets\n",
    "    train_ds, valid_ds = data.TabularDataset.splits(PATH, \n",
    "                                                    train=f'train_ds_{i}_of_{n_folds}.csv', \n",
    "                                                    validation=f'valid_ds_{i}_of_{n_folds}.csv',\n",
    "                                                    format='csv', skip_header=True, fields=train_datafields)\n",
    "\n",
    "    # train/validation iterators/dataloaders\n",
    "    train_iter, val_iter = data.BucketIterator.splits(\n",
    "        (train_ds, valid_ds), # we pass in the datasets we want the iterator to draw data from\n",
    "        batch_sizes=(batch_sizes[0], batch_sizes[1]),\n",
    "        device=0, # if you want to use the GPU, specify the GPU number here\n",
    "        sort_key=lambda x: len(x.comment_text_cleaned), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "        sort_within_batch=False,\n",
    "        repeat=False) # we pass repeat=False because we want to wrap this Iterator layer.\n",
    "        \n",
    "    train_dl = BatchWrapper(train_iter, txt_col, label_cols)\n",
    "    valid_dl = BatchWrapper(val_iter, txt_col, label_cols)\n",
    "        \n",
    "    md = ModelData(PATH, trn_dl=train_dl, val_dl=valid_dl, test_dl=test_dl)\n",
    "    \n",
    "    model = SimpleGru(vocab_sz, emb_sz, n_rnn_hidden, n_rnn_layers, True, out_sz, bsz=batch_sizes[0],\n",
    "                             linears=linears, linear_drops=linear_drops, use_bn=use_bn)\n",
    "    \n",
    "    model.cuda()\n",
    "    \n",
    "    lo = LayerOptimizer(optim.Adam, model, 1e-2, 1e-5)\n",
    "    on_end = lambda sched, cycle: save_model(model, f'{PATH}/models/fit_1_cv{i}_cyc_{cycle}')\n",
    "    cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2)] #, on_cycle_end=on_end)]\n",
    "    fit(model, md, 2**4-1, lo.opt, F.binary_cross_entropy, callbacks=cb)\n",
    "        \n",
    "    on_end = lambda sched, cycle: save_model(model, f'{PATH}/models/fit_2_cv{i}_cyc_{cycle}')\n",
    "    lo = LayerOptimizer(optim.Adam, model, 1e-3, 1e-5)\n",
    "    cb = [CosAnneal(lo, (len(md.trn_dl) * 6))] #, on_cycle_end=on_end)]\n",
    "    fit(model, md, 6, lo.opt, F.binary_cross_entropy, callbacks=cb)\n",
    "        \n",
    "    preds = predict(model, test_dl)\n",
    "        \n",
    "    subm_df = pd.read_csv(\"data/test.csv\")\n",
    "    for lbl_idx, col in enumerate([\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]):\n",
    "        subm_df[col] = preds[:, lbl_idx]\n",
    "        \n",
    "    # if you want to write the submission file to disk, uncomment and run the below code\n",
    "    subm_df.drop(['comment_text'], axis=1).to_csv(f'{PATH}/submissions/subm_lstm_cv_{i}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1531640"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.996244</td>\n",
       "      <td>0.393182</td>\n",
       "      <td>0.972876</td>\n",
       "      <td>0.087797</td>\n",
       "      <td>0.935190</td>\n",
       "      <td>0.310491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.996244  0.393182      0.972876  0.087797  0.935190   \n",
       "1  0000247867823ef7  0.001040  0.000051      0.001035  0.000020  0.000553   \n",
       "\n",
       "   identity_hate  \n",
       "0  0.310491       \n",
       "1  0.000119       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_dfs = []\n",
    "for i in range(n_folds):\n",
    "    df = pd.read_csv(f'{PATH}/submissions/subm_lstm_cv_{i}.csv')\n",
    "    cv_dfs.append(df)\n",
    "    \n",
    "final_cv_df = pd.concat([ df for df in cv_dfs ])\n",
    "\n",
    "display(len(final_cv_df))\n",
    "display(final_cv_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.900280</td>\n",
       "      <td>0.375404</td>\n",
       "      <td>0.875346</td>\n",
       "      <td>0.087246</td>\n",
       "      <td>0.826584</td>\n",
       "      <td>0.242148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.000360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.030315</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.022104</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.014694</td>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.900280  0.375404      0.875346  0.087246  0.826584   \n",
       "1  0000247867823ef7  0.004881  0.000273      0.002911  0.000026  0.001958   \n",
       "2  00013b17ad220c46  0.030315  0.003812      0.022104  0.000283  0.014694   \n",
       "3  00017563c3f7919a  0.017715  0.001505      0.010097  0.001165  0.010401   \n",
       "4  00017695ad8997eb  0.012319  0.000488      0.004050  0.000300  0.002884   \n",
       "\n",
       "   identity_hate  \n",
       "0  0.242148       \n",
       "1  0.000360       \n",
       "2  0.001177       \n",
       "3  0.001894       \n",
       "4  0.000992       "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cv_df = final_cv_df.groupby(['id']).mean().reset_index()\n",
    "final_cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_cv_df.to_csv(f'{PATH}/submissions/subm_lstm_cv_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
